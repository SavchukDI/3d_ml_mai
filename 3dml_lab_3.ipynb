{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3dml_lab_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbxdmkJI3XdN+WQ6Ecb6Jw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SavchukDI/3d_ml_mai/blob/main/3dml_lab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pyredner\n",
        "import h5py\n",
        "import urllib\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "from matplotlib import animation\n",
        "\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "Sfg9mAs527am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Basel face model\n",
        "with h5py.File(r'model2017-1_bfm_nomouth.h5', 'r') as hf:\n",
        "    shape_mean = torch.tensor(hf['shape/model/mean'], \n",
        "                              device = pyredner.get_device())\n",
        "    shape_basis = torch.tensor(hf['shape/model/pcaBasis'], \n",
        "                               device = pyredner.get_device())\n",
        "    triangle_list = torch.tensor(hf['shape/representer/cells'], \n",
        "                                 device = pyredner.get_device())\n",
        "    color_mean = torch.tensor(hf['color/model/mean'], \n",
        "                              device = pyredner.get_device())\n",
        "    color_basis = torch.tensor(hf['color/model/pcaBasis'], \n",
        "                               device = pyredner.get_device())"
      ],
      "metadata": {
        "id": "9I6eKmv42_7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = triangle_list.permute(1, 0).contiguous()\n",
        "\n",
        "def model(\n",
        "        cam_pos, \n",
        "        cam_look_at, \n",
        "        shape_coeffs, \n",
        "        color_coeffs, \n",
        "        ambient_color, \n",
        "        dir_light_intensity):\n",
        "    vertices = (shape_mean + shape_basis @ shape_coeffs).view(-1, 3)\n",
        "    normals = pyredner.compute_vertex_normal(vertices, indices)\n",
        "    colors = (color_mean + color_basis @ color_coeffs).view(-1, 3)\n",
        "    m = pyredner.Material(use_vertex_color = True)\n",
        "    obj = pyredner.Object(vertices = vertices, \n",
        "                          indices = indices, \n",
        "                          normals = normals, \n",
        "                          material = m, \n",
        "                          colors = colors)\n",
        "    cam = pyredner.Camera(position = cam_pos,\n",
        "                          # Center of the vertices                          \n",
        "                          look_at = cam_look_at,\n",
        "                          up = torch.tensor([0.0, 1.0, 0.0]),\n",
        "                          fov = torch.tensor([45.0]),\n",
        "                          resolution = (256, 256))\n",
        "    scene = pyredner.Scene(camera = cam, objects = [obj])\n",
        "    ambient_light = pyredner.AmbientLight(ambient_color)\n",
        "    dir_light = pyredner.DirectionalLight(torch.tensor([0.0, 0.0, -1.0]), \n",
        "                                          dir_light_intensity)\n",
        "    img = pyredner.render_deferred(scene = scene, \n",
        "                                   lights = [ambient_light, dir_light])\n",
        "    return img"
      ],
      "metadata": {
        "id": "s0iF1LLT3BNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cam_pos = torch.tensor([-0.2697, -5.7891, 373.9277])\n",
        "cam_look_at = torch.tensor([-0.2697, -5.7891, 54.7918])\n",
        "img = model(cam_pos, \n",
        "            cam_look_at, \n",
        "            torch.zeros(199, device = pyredner.get_device()),\n",
        "            torch.zeros(199, device = pyredner.get_device()),\n",
        "            torch.ones(3), \n",
        "            torch.zeros(3))\n",
        "\n",
        "imshow(torch.pow(img, 1.0/2.2).cpu())\n",
        "\n",
        "face_url = 'https://raw.githubusercontent.com/BachiLi/redner/master/tutorials/mona-lisa-cropped-256.png'\n",
        "\n",
        "urllib.request.urlretrieve(face_url, 'target.png')\n",
        "target = pyredner.imread('target.png').to(pyredner.get_device())\n",
        "\n",
        "imshow(torch.pow(target, 1.0/2.2).cpu())"
      ],
      "metadata": {
        "id": "xRFgdLEq3DPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set requires_grad=True since we want to optimize them later\n",
        "cam_pos = torch.tensor([-0.2697, -5.7891, 373.9277], \n",
        "                       requires_grad=True)\n",
        "cam_look_at = torch.tensor([-0.2697, -5.7891, 54.7918], \n",
        "                           requires_grad=True)\n",
        "shape_coeffs = torch.zeros(199, device = pyredner.get_device(), \n",
        "                           requires_grad=True)\n",
        "color_coeffs = torch.zeros(199, device = pyredner.get_device(), \n",
        "                           requires_grad=True)\n",
        "ambient_color = torch.ones(3, device = pyredner.get_device(), \n",
        "                           requires_grad=True)\n",
        "dir_light_intensity = torch.zeros(3, device = pyredner.get_device(), \n",
        "                                  requires_grad=True)\n",
        "\n",
        "# Use two different optimizers for different learning rates\n",
        "optimizer = torch.optim.Adam(\n",
        "                             [\n",
        "                              shape_coeffs, \n",
        "                              color_coeffs, \n",
        "                              ambient_color, \n",
        "                              dir_light_intensity], \n",
        "                             lr=0.1)\n",
        "cam_optimizer = torch.optim.Adam([cam_pos, cam_look_at], lr=0.5)"
      ],
      "metadata": {
        "id": "H9f3wkm63EmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "imgs, losses = [], []\n",
        "\n",
        "# Run 500 Adam iterations\n",
        "num_iters = 500\n",
        "for t in range(num_iters):\n",
        "    optimizer.zero_grad()\n",
        "    cam_optimizer.zero_grad()\n",
        "    img = model(cam_pos, cam_look_at, shape_coeffs, \n",
        "                color_coeffs, ambient_color, dir_light_intensity)\n",
        "    # Compute the loss function. Here it is L2 plus a regularization \n",
        "    # term to avoid coefficients to be too far from zero.\n",
        "    # Both img and target are in linear color space, \n",
        "    # so no gamma correction is needed.\n",
        "\n",
        "    loss = (img - target).pow(2).mean()\n",
        "    loss = loss \n",
        "         + 0.0001 * shape_coeffs.pow(2).mean() \n",
        "         + 0.001 * color_coeffs.pow(2).mean()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    cam_optimizer.step()\n",
        "\n",
        "    ambient_color.data.clamp_(0.0)\n",
        "    dir_light_intensity.data.clamp_(0.0)\n",
        "\n",
        "    # Plot the loss\n",
        "    f, (ax_loss, ax_diff_img, ax_img) = plt.subplots(1, 3)\n",
        "    losses.append(loss.data.item())\n",
        "\n",
        "    # Only store images every 10th iterations\n",
        "    if t % 10 == 0:\n",
        "        # Record the Gamma corrected image\n",
        "        imgs.append(torch.pow(img.data, 1.0/2.2).cpu()) \n",
        "    clear_output(wait=True)\n",
        "    ax_loss.plot(range(len(losses)), losses, label='loss')\n",
        "    ax_loss.legend()\n",
        "    ax_diff_img.imshow((img -target).pow(2).sum(dim=2).data.cpu())\n",
        "    ax_img.imshow(torch.pow(img.data.cpu(), 1.0/2.2))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0nb1YHlw3Fvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "# Clamp to avoid complains\n",
        "im = plt.imshow(imgs[0].clamp(0.0, 1.0), animated=True)\n",
        "\n",
        "def update_fig(i):\n",
        "    im.set_array(imgs[i].clamp(0.0, 1.0))\n",
        "    return im,\n",
        "anim = animation.FuncAnimation(fig, update_fig, \n",
        "                               frames=len(imgs), interval=50, blit=True)\n",
        "HTML(anim.to_jshtml())"
      ],
      "metadata": {
        "id": "InVP8Nhr3Gz7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}